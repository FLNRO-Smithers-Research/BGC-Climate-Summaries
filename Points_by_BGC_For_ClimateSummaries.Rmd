---
title: "RandomPoints by Spatial BGC"
author: "William H MacKenzie"
date: "17/10/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
library(dplyr)
library(rgdal)
library(sp)
library(raster)
library(rgeos)
library(maptools)
library(magrittr)
library(tibble)
library(tidyr)
library(sf)
library(tcltk)
library(foreach)
library(httr)
library(jsonlite)
library(randomForest)
library(data.table)
require(survey)
```

## Random Points from Existing BGC Spatial Mapping Layers


```{r random points by BC BGC}

dem <- raster("./inputs/SpatialFiles/bc25fill") ###Read DEM
bec11 <- st_read(dsn="./inputs/SpatialFiles/BGCv11_WithLandcover.gdb",layer="BGCv11_withLandcover") ##read BGC shape file - updated to clipped version
CRS.albers <- CRS ("+proj=aea +lat_1=50 +lat_2=58.5 +lat_0=45 +lon_0=-126 +x_0=1000000 +y_0=0 +datum=NAD83 +units=m +no_defs")
allUnits <- unique(as.character(bec11$MAP_LABEL))###What units are in BEC?
allUnits <- allUnits[allUnits !=""]
##set up for parallel processing
require(doParallel)
set.seed(123321)
coreNum <- as.numeric(detectCores()-1)
coreNo <- makeCluster(coreNum)
registerDoParallel(coreNo, cores = coreNum)

#BGC = "CWH wh 1"

###randomly select  points within each BEC unit and get elevation data
out <- foreach(BGC = allUnits, .combine = rbind, .packages = c("sf","sp","raster")) %dopar% {
  temp <- bec11$Shape[bec11$MAP_LABEL == BGC] ###Extract polygons for each subzones
  temp <- as(temp, "Spatial") ##conver to sp
  p <- spsample(temp, 100, type = "regular", offset = c(0, 0)) #, iter = 15   change for number of points here
  p <- spTransform(p, CRS("+init=epsg:4617")) #to lat lon in NAD83
    #p <- spTransform(p, CRS("+init=epsg:4326")) #to lat lon in WGS84
  coords <- p@coords
  coords <- as.data.frame(coords)
  
 p2 <- spTransform(p, CRS(proj4string(dem)))
 coords$elevation <- raster::extract(dem,p2) ##get elevation for each point
  coords$BGC <- BGC
  coords
}
stopCluster(coreNo)
out2 <- rename(out, "longitude" = "x1", "latitude" = "x2", "elevation" = "el")
out2 <- out2[out2$lat < 60,]
out2 = out2[,c("BGC", "lat","lon","el")]
write.csv(out2,"BECv11_100Pt_Reg.csv", row.names = TRUE)
```

### For Alberta


```{r random points by AB BGC, echo=FALSE}
####select random points from Alberta
ABdem <- raster("AlbertaDEM.tif")
ABSNR <- st_read(dsn="AlbertaNSR.gdb",layer="AlbertaBGC") ##read BGC shape file - updated to clipped version
CRS.albers <- CRS ("+proj=aea +lat_1=50 +lat_2=58.5 +lat_0=45 +lon_0=-126 +x_0=1000000 +y_0=0 +datum=NAD83 +units=m +no_defs")
allUnits <- unique(as.character(ABSNR$NRSSubzone))###What units are in AB?
allUnits <- allUnits[allUnits !=""]
##set up for parallel processing
require(doParallel)
set.seed(123321)
coreNum <- as.numeric(detectCores()-1)
coreNo <- makeCluster(coreNum)
registerDoParallel(coreNo, cores = coreNum)
clusterEvalQ(coreNo, .libPaths("E:/R packages351"))
#BGC = "NM"
###randomly select 2000 points within each BEC unit and get elevation data
out <- foreach(BGC = allUnits, .combine = rbind, .packages = c("sf","sp","raster")) %dopar% {
  temp <- ABSNR$Shape[ABSNR$NRSSubzone == BGC] ###Extract polygons for each subzones
  temp <- as(temp, "Spatial") ##conver to sp
  p <- spsample(temp, 500, type = "random") #, iter = 15change for number of points here
  #p <- spTransform(p, CRS("+init=epsg:4326")) #to lat lon
  p <- spTransform(p, CRS("+init=epsg:4617")) #to lat lon in NAD83
  coords <- p@coords
  coords <- as.data.frame(coords)
  
  p2 <- spTransform(p, CRS(proj4string(ABdem)))
  coords$Elevation <- raster::extract(ABdem,p2) ##get elevation for each point
  coords$BGC <- BGC
  coords
}
stopCluster(coreNo)
out2 <- out[out$y < 60,]
out2 = out2[,c("BGC", "y","x","Elevation")]
write.csv(out2,"AlbertaSNR_500Pt.csv", row.names = TRUE) ##rename for version and number of points
#### from here submit to ClimateWNA to retrieve climate variable data
```
